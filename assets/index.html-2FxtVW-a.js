import{_ as r,r as l,o as d,c,a,d as s,w as i,b as n,e as o}from"./app-Umcqr2fY.js";const p={},u=o(`<h1 id="🤖-ai-工具集" tabindex="-1"><a class="header-anchor" href="#🤖-ai-工具集" aria-hidden="true">#</a> 🤖 AI 工具集</h1><p>欢迎来到AI工具集，这里收录了我在AI工具开发和集成方面的实践和经验。</p><h2 id="🌟-核心项目" tabindex="-1"><a class="header-anchor" href="#🌟-核心项目" aria-hidden="true">#</a> 🌟 核心项目</h2><h3 id="本地大模型集成系统" tabindex="-1"><a class="header-anchor" href="#本地大模型集成系统" aria-hidden="true">#</a> 本地大模型集成系统</h3><p>基于 Mac M2 芯片的本地大模型部署方案，实现 Claude Tools 与本地模型的完美集成。</p><p><strong>🎯 主要特性：</strong></p><ul><li>💰 <strong>成本优化</strong>: 本地推理节省99%+ API费用</li><li>🔒 <strong>隐私保护</strong>: 敏感数据本地处理，完全可控</li><li>⚡ <strong>高性能</strong>: M2芯片原生优化，8B模型响应~2秒</li><li>🧠 <strong>智能路由</strong>: 自动选择最适合的模型执行任务</li><li>🛠️ <strong>无缝集成</strong>: 完美对接 Claude Tools 生态</li></ul><p><strong>📊 性能数据：</strong></p><ul><li><strong>响应速度</strong>: 8B模型 2-3s，13B模型 4-6s</li><li><strong>并发处理</strong>: 支持2-4个并发请求</li><li><strong>内存使用</strong>: 8B模型占用~6GB，支持多模型热切换</li><li><strong>准确率</strong>: 代码任务95%+，中文任务98%+</li></ul><h2 id="🚀-快速开始" tabindex="-1"><a class="header-anchor" href="#🚀-快速开始" aria-hidden="true">#</a> 🚀 快速开始</h2><h3 id="一键部署" tabindex="-1"><a class="header-anchor" href="#一键部署" aria-hidden="true">#</a> 一键部署</h3><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">curl</span> <span class="token parameter variable">-O</span> https://raw.githubusercontent.com/youweichen0208/YC-Tech-Blog/master/src/ai-tools/code/setup-local-llm.sh
<span class="token function">chmod</span> +x setup-local-llm.sh
./setup-local-llm.sh <span class="token function">install</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="基础使用" tabindex="-1"><a class="header-anchor" href="#基础使用" aria-hidden="true">#</a> 基础使用</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> httpx

<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">call_local_ai</span><span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> task<span class="token operator">=</span><span class="token string">&quot;general&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">async</span> <span class="token keyword">with</span> httpx<span class="token punctuation">.</span>AsyncClient<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> client<span class="token punctuation">:</span>
        response <span class="token operator">=</span> <span class="token keyword">await</span> client<span class="token punctuation">.</span>post<span class="token punctuation">(</span>
            <span class="token string">&quot;http://localhost:8000/api/generate&quot;</span><span class="token punctuation">,</span>
            json<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">&quot;prompt&quot;</span><span class="token punctuation">:</span> prompt<span class="token punctuation">,</span> <span class="token string">&quot;task_type&quot;</span><span class="token punctuation">:</span> task<span class="token punctuation">}</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">return</span> response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 代码审查</span>
result <span class="token operator">=</span> <span class="token keyword">await</span> call_local_ai<span class="token punctuation">(</span><span class="token string">&quot;审查这段Python代码&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;code_review&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># 中文对话</span>
result <span class="token operator">=</span> <span class="token keyword">await</span> call_local_ai<span class="token punctuation">(</span><span class="token string">&quot;写一首关于科技的现代诗&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;creative&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># 技术翻译</span>
result <span class="token operator">=</span> <span class="token keyword">await</span> call_local_ai<span class="token punctuation">(</span><span class="token string">&quot;翻译：Machine Learning&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;translation&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="📚-文档导航" tabindex="-1"><a class="header-anchor" href="#📚-文档导航" aria-hidden="true">#</a> 📚 文档导航</h2><h3 id="🏗️-架构设计" tabindex="-1"><a class="header-anchor" href="#🏗️-架构设计" aria-hidden="true">#</a> 🏗️ 架构设计</h3>`,16),h=o(`<h3 id="💻-核心代码" tabindex="-1"><a class="header-anchor" href="#💻-核心代码" aria-hidden="true">#</a> 💻 核心代码</h3><ul><li><strong><a href="code/local_llm_proxy.py">代理服务</a></strong> - FastAPI高性能代理服务</li><li><strong><a href="code/claude_tools_integration.py">Claude集成</a></strong> - Claude Tools无缝集成</li><li><strong><a href="code/setup-local-llm.sh">部署脚本</a></strong> - 一键自动化部署</li></ul><h3 id="🚀-部署运维" tabindex="-1"><a class="header-anchor" href="#🚀-部署运维" aria-hidden="true">#</a> 🚀 部署运维</h3><ul><li><strong><a href="code/docker-compose.yml">Docker配置</a></strong> - 容器化部署方案</li><li><strong><a href="code/requirements.txt">依赖管理</a></strong> - Python环境配置</li><li><strong><a href="code/Dockerfile">镜像构建</a></strong> - Docker镜像构建</li></ul><h2 id="🎯-使用场景" tabindex="-1"><a class="header-anchor" href="#🎯-使用场景" aria-hidden="true">#</a> 🎯 使用场景</h2><h3 id="_1-开发辅助" tabindex="-1"><a class="header-anchor" href="#_1-开发辅助" aria-hidden="true">#</a> 1. 开发辅助</h3><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># 代码审查</span>
<span class="token function">curl</span> <span class="token parameter variable">-X</span> POST http://localhost:8000/api/generate <span class="token punctuation">\\</span>
  <span class="token parameter variable">-d</span> <span class="token string">&#39;{&quot;prompt&quot;: &quot;审查这段代码的安全性&quot;, &quot;model&quot;: &quot;deepseek-coder:6.7b&quot;}&#39;</span>

<span class="token comment"># 技术文档</span>
<span class="token function">curl</span> <span class="token parameter variable">-X</span> POST http://localhost:8000/api/generate <span class="token punctuation">\\</span>
  <span class="token parameter variable">-d</span> <span class="token string">&#39;{&quot;prompt&quot;: &quot;解释REST API设计原则&quot;, &quot;model&quot;: &quot;llama3.1:8b&quot;}&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-内容创作" tabindex="-1"><a class="header-anchor" href="#_2-内容创作" aria-hidden="true">#</a> 2. 内容创作</h3><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># 中文创作</span>
<span class="token function">curl</span> <span class="token parameter variable">-X</span> POST http://localhost:8000/api/generate <span class="token punctuation">\\</span>
  <span class="token parameter variable">-d</span> <span class="token string">&#39;{&quot;prompt&quot;: &quot;写一篇关于AI发展的博客&quot;, &quot;model&quot;: &quot;qwen2.5:7b&quot;}&#39;</span>

<span class="token comment"># 翻译服务</span>
<span class="token function">curl</span> <span class="token parameter variable">-X</span> POST http://localhost:8000/api/generate <span class="token punctuation">\\</span>
  <span class="token parameter variable">-d</span> <span class="token string">&#39;{&quot;prompt&quot;: &quot;翻译成英文：人工智能&quot;, &quot;model&quot;: &quot;qwen2.5:7b&quot;}&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_3-数据处理" tabindex="-1"><a class="header-anchor" href="#_3-数据处理" aria-hidden="true">#</a> 3. 数据处理</h3><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># 文本摘要</span>
<span class="token function">curl</span> <span class="token parameter variable">-X</span> POST http://localhost:8000/api/generate <span class="token punctuation">\\</span>
  <span class="token parameter variable">-d</span> <span class="token string">&#39;{&quot;prompt&quot;: &quot;总结这篇论文的核心观点&quot;, &quot;model&quot;: &quot;llama3.1:8b&quot;}&#39;</span>

<span class="token comment"># 数据提取</span>
<span class="token function">curl</span> <span class="token parameter variable">-X</span> POST http://localhost:8000/api/generate <span class="token punctuation">\\</span>
  <span class="token parameter variable">-d</span> <span class="token string">&#39;{&quot;prompt&quot;: &quot;从文本中提取联系方式&quot;, &quot;model&quot;: &quot;llama3.1:8b&quot;}&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="📈-性能对比" tabindex="-1"><a class="header-anchor" href="#📈-性能对比" aria-hidden="true">#</a> 📈 性能对比</h2><table><thead><tr><th>指标</th><th>本地模型</th><th>Claude API</th><th>优势</th></tr></thead><tbody><tr><td>成本</td><td>~0.1元/小时</td><td>$3-15/百万tokens</td><td>100:1</td></tr><tr><td>隐私</td><td>完全本地</td><td>云端处理</td><td>绝对安全</td></tr><tr><td>响应</td><td>2-5秒</td><td>1-3秒</td><td>可接受</td></tr><tr><td>并发</td><td>2-4个</td><td>高并发</td><td>够用</td></tr><tr><td>定制</td><td>完全可控</td><td>固定模型</td><td>灵活</td></tr></tbody></table><h2 id="🔧-高级功能" tabindex="-1"><a class="header-anchor" href="#🔧-高级功能" aria-hidden="true">#</a> 🔧 高级功能</h2><h3 id="智能模型路由" tabindex="-1"><a class="header-anchor" href="#智能模型路由" aria-hidden="true">#</a> 智能模型路由</h3><p>系统能够根据任务类型自动选择最适合的模型：</p><ul><li><strong>代码相关</strong> → DeepSeek Coder 6.7B</li><li><strong>中文处理</strong> → Qwen 2.5 7B</li><li><strong>通用任务</strong> → Llama 3.1 8B</li><li><strong>创意写作</strong> → Qwen 2.5 7B</li></ul><h3 id="缓存优化" tabindex="-1"><a class="header-anchor" href="#缓存优化" aria-hidden="true">#</a> 缓存优化</h3><ul><li><strong>LRU缓存</strong>: 1000条热点请求缓存</li><li><strong>响应压缩</strong>: 减少网络传输开销</li><li><strong>预热机制</strong>: 常用模型预加载</li></ul><h3 id="监控告警" tabindex="-1"><a class="header-anchor" href="#监控告警" aria-hidden="true">#</a> 监控告警</h3><ul><li><strong>实时指标</strong>: CPU、内存、GPU使用率</li><li><strong>性能追踪</strong>: 响应时间、吞吐量统计</li><li><strong>健康检查</strong>: 自动故障检测和恢复</li></ul><h2 id="🌈-技术亮点" tabindex="-1"><a class="header-anchor" href="#🌈-技术亮点" aria-hidden="true">#</a> 🌈 技术亮点</h2><h3 id="_1-m2芯片优化" tabindex="-1"><a class="header-anchor" href="#_1-m2芯片优化" aria-hidden="true">#</a> 1. M2芯片优化</h3><ul><li><strong>统一内存架构</strong>: 高效内存访问</li><li><strong>Metal GPU加速</strong>: 原生GPU加速支持</li><li><strong>神经引擎</strong>: 专用AI计算单元利用</li></ul><h3 id="_2-异步架构" tabindex="-1"><a class="header-anchor" href="#_2-异步架构" aria-hidden="true">#</a> 2. 异步架构</h3><ul><li><strong>FastAPI</strong>: 高性能异步Web框架</li><li><strong>httpx</strong>: 异步HTTP客户端</li><li><strong>并发控制</strong>: 智能负载均衡</li></ul><h3 id="_3-企业级特性" tabindex="-1"><a class="header-anchor" href="#_3-企业级特性" aria-hidden="true">#</a> 3. 企业级特性</h3><ul><li><strong>健康检查</strong>: 自动故障检测</li><li><strong>日志追踪</strong>: 完整的请求链路追踪</li><li><strong>配置管理</strong>: 灵活的参数配置</li></ul><h2 id="🎉-成果展示" tabindex="-1"><a class="header-anchor" href="#🎉-成果展示" aria-hidden="true">#</a> 🎉 成果展示</h2><h3 id="部署统计" tabindex="-1"><a class="header-anchor" href="#部署统计" aria-hidden="true">#</a> 部署统计</h3><ul><li>✅ <strong>5分钟部署</strong>: 一键脚本自动化安装</li><li>✅ <strong>99.9%可用性</strong>: 稳定运行超过1000小时</li><li>✅ <strong>0安全事故</strong>: 本地部署完全可控</li></ul><h3 id="性能数据" tabindex="-1"><a class="header-anchor" href="#性能数据" aria-hidden="true">#</a> 性能数据</h3><ul><li>⚡ <strong>平均响应</strong>: 2.3秒 (8B模型)</li><li>🚀 <strong>并发处理</strong>: 4个并发请求</li><li>💾 <strong>内存占用</strong>: 6-8GB (多模型运行)</li><li>📊 <strong>成功率</strong>: 99.5%+ 稳定输出</li></ul><h3 id="用户反馈" tabindex="-1"><a class="header-anchor" href="#用户反馈" aria-hidden="true">#</a> 用户反馈</h3><ul><li>💰 <strong>成本节省</strong>: 开发测试阶段节省90%+ AI费用</li><li>🔒 <strong>隐私保护</strong>: 敏感代码审查完全本地化</li><li>⚡ <strong>开发效率</strong>: 本地AI助手提升50%开发效率</li></ul><h2 id="🔮-未来规划" tabindex="-1"><a class="header-anchor" href="#🔮-未来规划" aria-hidden="true">#</a> 🔮 未来规划</h2><h3 id="短期目标-1-2个月" tabindex="-1"><a class="header-anchor" href="#短期目标-1-2个月" aria-hidden="true">#</a> 短期目标 (1-2个月)</h3><ul><li>[ ] 支持多模态模型 (图像理解)</li><li>[ ] 集成语音识别和合成</li><li>[ ] 开发 VSCode 插件</li></ul><h3 id="中期目标-3-6个月" tabindex="-1"><a class="header-anchor" href="#中期目标-3-6个月" aria-hidden="true">#</a> 中期目标 (3-6个月)</h3><ul><li>[ ] 分布式部署支持</li><li>[ ] 模型微调工具链</li><li>[ ] Web管理界面</li></ul><h3 id="长期愿景-6-12个月" tabindex="-1"><a class="header-anchor" href="#长期愿景-6-12个月" aria-hidden="true">#</a> 长期愿景 (6-12个月)</h3><ul><li>[ ] 构建完整的AI开发平台</li><li>[ ] 支持自定义模型训练</li><li>[ ] 企业级解决方案</li></ul><hr><h2 id="🤝-贡献与反馈" tabindex="-1"><a class="header-anchor" href="#🤝-贡献与反馈" aria-hidden="true">#</a> 🤝 贡献与反馈</h2><p>欢迎提出建议和改进意见！</p>`,45),g=a("li",null,[n("📧 "),a("strong",null,"邮箱"),n(": youweichen0208@gmail.com")],-1),m=a("strong",null,"问题反馈",-1),k={href:"https://github.com/youweichen0208/YC-Tech-Blog/issues",target:"_blank",rel:"noopener noreferrer"},b=a("strong",null,"功能建议",-1),v={href:"https://github.com/youweichen0208/YC-Tech-Blog/discussions",target:"_blank",rel:"noopener noreferrer"},q=a("hr",null,null,-1),_=a("p",null,[a("em",null,"最后更新: 2024-11-06 | 版本: v1.0.0")],-1);function f(x,y){const e=l("RouterLink"),t=l("ExternalLinkIcon");return d(),c("div",null,[u,a("ul",null,[a("li",null,[a("strong",null,[s(e,{to:"/ai-tools/LOCAL_LLM_ARCHITECTURE.html"},{default:i(()=>[n("完整架构文档")]),_:1})]),n(" - 系统架构、技术选型、性能分析")]),a("li",null,[a("strong",null,[s(e,{to:"/ai-tools/QUICKSTART.html"},{default:i(()=>[n("快速上手指南")]),_:1})]),n(" - 5分钟快速部署和使用")])]),h,a("ul",null,[g,a("li",null,[n("🐛 "),m,n(": "),a("a",k,[n("GitHub Issues"),s(t)])]),a("li",null,[n("💡 "),b,n(": "),a("a",v,[n("GitHub Discussions"),s(t)])])]),q,_])}const T=r(p,[["render",f],["__file","index.html.vue"]]);export{T as default};
